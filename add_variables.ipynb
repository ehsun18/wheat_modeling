{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tavg_cal(df):\n",
    "    df['Tavg'] = (df['tmax'] + df['tmin'])/2\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def doy_cal(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Adds a Day of Year (DOY) column to a DataFrame and inserts it as the second column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the date column.\n",
    "        date_column (str): The name of the column with date values (default is 'date').\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an added 'DOY' column as the second column.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Add the DOY column\n",
    "    df.insert(1, 'doy', df[date_column].dt.dayofyear)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def dap_cal(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Adds a column to calculate days after the planting date,\n",
    "    where the planting date is the first date in the dataset for each year.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the date column.\n",
    "        date_column (str): Name of the column with date values (default is 'date').\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with a new 'days_after_planting' column.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Sort the DataFrame by date\n",
    "    #df = df.sort_values(by=date_column)\n",
    "    \n",
    "    # Determine the first date of each year (planting date)\n",
    "    df['planting_date'] = df.groupby(df[date_column].dt.year)[date_column].transform('min')\n",
    "    \n",
    "    # Calculate days after planting\n",
    "    \n",
    "    df.insert(2, 'dap',(df[date_column] - df['planting_date']).dt.days)\n",
    "    # Drop the 'planting_date' column if not needed\n",
    "    df.drop(columns=['planting_date'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#define GDD function:\n",
    "def gdd_cal(Tdata):\n",
    "    Tdata['gdd'] = Tdata.apply(\n",
    "    lambda row: 0 if row['Tavg'] < 0\n",
    "    else 30 - 0 if row['Tavg'] > 30\n",
    "    else row['Tavg'] - 0, axis=1\n",
    "    \n",
    ")\n",
    "    \n",
    "#define dgdd function\n",
    "def dgdd_cal(df):\n",
    "    # Calculate the difference in 'gdd' between each row and the previous row\n",
    "    df['dgdd'] = abs(df['gdd'].diff().fillna(0))\n",
    "    return df\n",
    "\n",
    "#define dtr function\n",
    "def dtr_cal(df):\n",
    "    # Calculate the difference in 'gdd' between each row and the previous row\n",
    "    df['dtr'] = df['tmax'] - df['tmin']\n",
    "    return df\n",
    "\n",
    "def prdtr_cal(df):\n",
    "    # Calculate the difference in 'gdd' between each row and the previous row\n",
    "    df['prdtr'] = df['precip']  / df['dtr']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cum_gdd(df, date_column='date', tavg_column='Tavg', lower_threshold=0, upper_threshold=30):\n",
    "    \"\"\"\n",
    "    Calculates cumulative GDD with thresholds of 0 and 30°C, resetting at the start of each year.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing daily temperature data.\n",
    "        date_column (str): Name of the column with dates.\n",
    "        tavg_column (str): Name of the column with average daily temperature.\n",
    "        lower_threshold (float): Lower threshold for GDD (default = 0°C).\n",
    "        upper_threshold (float): Upper threshold for GDD (default = 30°C).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'Cumulative_GDD' column that resets each year.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Extract year from the date\n",
    "    df['Year'] = df[date_column].dt.year\n",
    "    \n",
    "    # Calculate daily GDD with thresholds\n",
    "    df['GDD'] = df[tavg_column].apply(\n",
    "        lambda t: max(0, min(upper_threshold, t) - lower_threshold)\n",
    "    )\n",
    "    \n",
    "    # Calculate cumulative GDD for each year\n",
    "    df['cum_gdd'] = df.groupby('Year')['GDD'].cumsum()\n",
    "    \n",
    "    # Drop intermediate columns if necessary\n",
    "    df.drop(columns=['GDD', 'Year'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage(df, cumulative_gdd_column='cum_gdd'):\n",
    "    \"\"\"\n",
    "    Assigns phenological stages to each row based on cumulative GDD values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing cumulative GDD data.\n",
    "        cumulative_gdd_column (str): Column name for cumulative GDD values.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'Phenological_Stage' column.\n",
    "    \"\"\"\n",
    "    # Define phenological stages and their cumulative GDD ranges\n",
    "    stages = [\n",
    "        (0, 110, 'Emergence'),\n",
    "        (110, 440, 'Tillering'),\n",
    "        (440, 670, 'Jointing'),\n",
    "        (670, 1100, 'Heading'),\n",
    "        (1100, 1300, 'Flowering'),\n",
    "        (1300, 1675, 'Grain fill'),\n",
    "        (1675, 1800, 'Maturity')\n",
    "    ]\n",
    "    \n",
    "    # Function to determine the stage based on cumulative GDD\n",
    "    def get_stage(cumulative_gdd):\n",
    "        for lower, upper, stage in stages:\n",
    "            if lower <= cumulative_gdd < upper:\n",
    "                return stage\n",
    "        return 'Beyond Maturity'  # For GDD > 1800\n",
    "    \n",
    "    # Apply the stage determination function to the cumulative GDD column\n",
    "    df.insert(3,'stage',df[cumulative_gdd_column].apply(get_stage))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndirectory_path = \\'./planting_heading_daily_variables\\'\\noutput_directory = \\'./v\\'\\n\\nfor filename in os.listdir(directory_path):\\n    if filename.endswith(\\'.xlsx\\'):\\n        try:\\n            file_path = os.path.join(directory_path, filename)\\n            data = pd.read_excel(file_path)\\n            # Convert Date to datetime\\n            data[\\'date\\'] = pd.to_datetime(df[\\'date\\'])\\n            # Calculate FDD and HDD\\n            df, cumulative_results = cal_fdd_hdd(data, cl_thresholds, ch_thresholds)\\n\\n            # Create a unique output file path\\n            output_file_path = os.path.join(output_directory, filename.replace(\\'.csv\\', \\'.xlsx\\'))\\n            data.to_excel(output_file_path, index=False)\\n        except Exception as e:\\n            print(f\"Error processing {filename}: {e}\")\\n            \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def cal_fdd_hdd(df, cl_values, ch_values):\n",
    "    \"\"\"\n",
    "    Calculates FDD and HDD for each crop growth stage based on CL and CH thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing daily temperature data and growth stages.\n",
    "                          Columns: 'Date', 'Tavg', 'Stage'\n",
    "        cl_values (dict): Dictionary of Critical Low (CL) thresholds for each stage.\n",
    "                          Example: {'Emergence': -17.2, 'Tillering': -17.2, ...}\n",
    "        ch_values (dict): Dictionary of Critical High (CH) thresholds for each stage.\n",
    "                          Example: {'Emergence': 22.79, 'Tillering': 20.90, ...}\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with added 'FDD' and 'HDD' columns.\n",
    "    \"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Initialize FDD and HDD columns\n",
    "    df['fdd'] = df.apply(lambda row: max(0, cl_values[row['stage']] - row['tmin']), axis=1)\n",
    "    df['hdd'] = df.apply(lambda row: max(0, row['tmax'] - ch_values[row['stage']]), axis=1)\n",
    "    \n",
    "    # Group by Stage to calculate cumulative FDD and HDD\n",
    "    grouped = df.groupby('stage').agg(\n",
    "        Cumulative_FDD=('fdd', 'sum'),\n",
    "        Cumulative_HDD=('hdd', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    return df, grouped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define CL and CH thresholds for each stage\n",
    "cl_thresholds = {\n",
    "    'Emergence': 4.23,\n",
    "    'Tillering': 5.26,\n",
    "    'Jointing': 2.02,\n",
    "    'Heading': 2.99,\n",
    "    'Flowering': 11.12,\n",
    "    'Grain fill': 14.45,\n",
    "    'Maturity':14.45,\n",
    "    'Beyond Maturity': 14.45\n",
    "}\n",
    "\n",
    "ch_thresholds = {\n",
    "    'Emergence': 22.79,\n",
    "    'Tillering': 20.90,\n",
    "    'Jointing': 22.55,\n",
    "    'Heading': 20,\n",
    "    'Flowering': 27,\n",
    "    'Grain fill': 30,\n",
    "    'Maturity':30,\n",
    "    'Beyond Maturity': 30\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "directory_path = './planting_heading_daily_variables'\n",
    "output_directory = './v'\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        try:\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            data = pd.read_excel(file_path)\n",
    "            # Convert Date to datetime\n",
    "            data['date'] = pd.to_datetime(df['date'])\n",
    "            # Calculate FDD and HDD\n",
    "            df, cumulative_results = cal_fdd_hdd(data, cl_thresholds, ch_thresholds)\n",
    "\n",
    "            # Create a unique output file path\n",
    "            output_file_path = os.path.join(output_directory, filename.replace('.csv', '.xlsx'))\n",
    "            data.to_excel(output_file_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory_path = './planting_heading_daily_variables'\n",
    "output_directory = './v'\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        try:\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            data = pd.read_excel(file_path)\n",
    "\n",
    "            # Apply calculations\n",
    "            Tavg_cal(data)\n",
    "            gdd_cal(data)\n",
    "            dgdd_cal(data)\n",
    "            dtr_cal(data)\n",
    "            prdtr_cal(data)\n",
    "            doy_cal(data)\n",
    "            dap_cal(data)\n",
    "            cum_gdd(data)\n",
    "            stage(data)\n",
    "            df, cumulative_results = cal_fdd_hdd(data, cl_thresholds, ch_thresholds)\n",
    "            # Create a unique output file path\n",
    "            output_file_path = os.path.join(output_directory, filename.replace('.csv', '.xlsx'))\n",
    "            data.to_excel(output_file_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
