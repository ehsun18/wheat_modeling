{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec94d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw data from planting to heading date\n",
    "loc_files = './soil' # <--- address to raw data here\n",
    "\n",
    "wheat_df = pd.read_excel('sws_spring_wheat.xlsx',sheet_name='Sheet2')\n",
    "for file_name in os.listdir(loc_files):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Load the datasets\n",
    "        file_path = os.path.join(loc_files,file_name)\n",
    "        loc_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "        # Convert date columns to datetime format\n",
    "        loc_df['date'] = pd.to_datetime(loc_df['date'])\n",
    "        wheat_df['planting date'] = pd.to_datetime(wheat_df['planting date'])\n",
    "        wheat_df['harvest date'] = pd.to_datetime(wheat_df['harvest date'])\n",
    "\n",
    "        # Initialize an empty DataFrame to store the filtered results\n",
    "        filtered_df = pd.DataFrame()\n",
    "        location, extension = os.path.splitext(file_name)\n",
    "        # Loop through each row of the growth data frame (sws_spring_wheat)\n",
    "        for index, row in wheat_df.iterrows():\n",
    "            if row['location'] == location:\n",
    "                # Filter rows where the date is between the planting and harvest dates for the respective year\n",
    "                mask = (loc_df['date'] >= row['planting date']) & (loc_df['date'] <= row['harvest date'])\n",
    "                filtered_data = loc_df[mask]\n",
    "                # Append the filtered data to the filtered_df\n",
    "                filtered_df = pd.concat([filtered_df, filtered_data], ignore_index=True)\n",
    "                \n",
    "        output_file_path = os.path.join('./soil_p_h', f'{file_name}')\n",
    "        filtered_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the new filters variable to the old data ###\n",
    "file_path1 = './test' # <--- address to old data here\n",
    "file_path2 = './pdsi_p_h' # <--- address to new data here\n",
    "output_path = './p_h_with_strs' # <--- address to output data here\n",
    "excel_files = [f for f in os.listdir(file_path1) if f.endswith('.xlsx')]\n",
    "\n",
    "for excel_f in excel_files:\n",
    "    df1 = pd.read_excel(os.path.join(file_path1, excel_f))\n",
    "    df2 = pd.read_excel(os.path.join(file_path2, excel_f))\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df2['date'] = pd.to_datetime(df2['date'])\n",
    "    # Mergge according to the data\n",
    "    df1 = df1.merge(df2[['date', 'pdsi']], on = 'date', how = 'left')\n",
    "    output_file = os.path.join(output_path, f'{os.path.splitext(excel_f)[0]}.xlsx')\n",
    "    df1.to_excel(output_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set dataframe. Taking average or sum of variables, considering which one makes sense, during their repsective growth stage ##\n",
    "\n",
    "file_path = './test1/' # <--- address to prepared daily data here\n",
    "\n",
    "# gs here stands for growth stage ##\n",
    "output_file_path = './gs_data/' # <--- address to aggregated data (weekly, montly, seasonal or growth stage) here\n",
    "# List all .xlsx files in the directory\n",
    "excel_files = [f for f in os.listdir(file_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Loop through each Excel file\n",
    "for excel_f in excel_files:\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(os.path.join(file_path, excel_f))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    gs_agg = df.groupby(['stage', 'year']).agg({\n",
    "            'precip': 'sum',\n",
    "            'tmax': 'mean',\n",
    "            'tmin': 'mean',\n",
    "            'Tavg': 'mean',\n",
    "            'gdd': 'sum',\n",
    "            'dgdd': 'sum',\n",
    "            'dtr': 'mean',\n",
    "            'prdtr': 'mean',\n",
    "            'pet': 'sum',\n",
    "            'etr': 'mean',\n",
    "            'srad': 'mean',\n",
    "            'rmax': 'mean',\n",
    "            'rmin': 'mean',\n",
    "            'vs': 'mean',\n",
    "            'ravg': 'mean',\n",
    "            'vpd': 'mean',\n",
    "            'fdd':'sum',\n",
    "            'hdd':'sum',\n",
    "            'spei':'mean',\n",
    "            'pdsi':'mean',\n",
    "            'soil':'mean'}).reset_index()\n",
    "    stage_order = {\"Emergence\": 0, \"Tillering\": 1, \"Jointing\": 2, \"Heading\": 3, \"Flowering\": 4, \"Grain fill\": 5, \"Maturity\": 6, \"Beyond Maturity\": 7}\n",
    "    gs_agg[\"stage_order\"] = gs_agg[\"stage\"].map(stage_order)\n",
    "    gs_agg = gs_agg.sort_values(by=[\"stage_order\",\"year\"]).drop(columns=\"stage_order\")\n",
    "    gs_agg = gs_agg.reset_index(drop=True)\n",
    "\n",
    "    # Calculate the number of days in each stage grouped by 'year' and 'stage'\n",
    "    days_per_stage_year = df.groupby(['year', 'stage'])['dap'].agg(lambda x: x.max() - x.min()).reset_index()\n",
    "    days_per_stage_year.rename(columns={'dap': '#days'}, inplace=True)\n",
    "\n",
    "    # Calculate the total number of wet days in each stage grouped by 'year' and 'stage'\n",
    "    wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
    "    wet_per_stage_year.rename(columns={'wet': '#wet'}, inplace=True)\n",
    "\n",
    "    # Merge the calculated values back into the aggregated dataset\n",
    "    gs_agg = gs_agg.merge(days_per_stage_year, on=['year', 'stage'], how='left')\n",
    "    gs_agg = gs_agg.merge(wet_per_stage_year, on=['year', 'stage'], how='left')\n",
    "\n",
    "    # Calculate wet frequency\n",
    "    gs_agg['wet_frequency'] = gs_agg['#wet'] / gs_agg['#days']\n",
    "\n",
    "    # Save the output to an Excel file\n",
    "    output_file = os.path.join(output_file_path, f'{os.path.splitext(excel_f)[0]}.xlsx')\n",
    "    gs_agg.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d21fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now data are in seperate files based on location names, So I need th combine them into one file\n",
    "## Combine all data frames ##\n",
    "directory = './gs_data'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\"):  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df = combined_df.drop(columns = ['#wet'])\n",
    "combined_df.to_excel('./combined_gs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rehape the data so it will have columns based on growth stage and evironmental variable ###\n",
    "\n",
    "# Define the order of the stages\n",
    "stage_order = [\"Emergence\", \"Tillering\", \"mature\", \"Jointing\", \"Heading\", \"Flowering\", \"Grain fill\", \"Maturity\", \"Beyond Maturity\"]  \n",
    "\n",
    "# Convert 'stage' to a categorical type with the specified order\n",
    "combined_df[\"stage\"] = pd.Categorical(combined_df[\"stage\"], categories=stage_order, ordered=True)\n",
    "\n",
    "# Pivot the data\n",
    "reshaped_df = combined_df.pivot(index=[\"year\", \"location\"], columns=\"stage\")\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "reshaped_df.columns = [f\"{col[1]}_{col[0]}\" for col in reshaped_df.columns]\n",
    "\n",
    "# Reset the index for a clean format\n",
    "reshaped_df.reset_index(inplace=True)\n",
    "# Save the reshaped DataFrame to an Excel file\n",
    "reshaped_df.to_excel('./reshaped_combined_gs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "## I want to add precipitation (or any other variable) before each growing season to the data  ##\n",
    "## I will sum up the precipitation from october until planting date to the data                ##\n",
    "#################################################################################################\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "loc_files = './spei' # <---- address to raw data here\n",
    "output_path = './spei_season' # <--- address to output added preseason data here\n",
    "wheat_df = pd.read_excel('sws_spring_wheat.xlsx',sheet_name='Sheet2')\n",
    "yearly_precip_sums = {}\n",
    "for file_name in os.listdir(loc_files):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Load the datasets\n",
    "        file_path = os.path.join(loc_files,file_name)\n",
    "        loc_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "        # Convert date columns to datetime format\n",
    "        loc_df['date'] = pd.to_datetime(loc_df['date'])\n",
    "        wheat_df['planting date'] = pd.to_datetime(wheat_df['planting date'])\n",
    "        #wheat_df['harvest date'] = pd.to_datetime(wheat_df['harvest date'])\n",
    "\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the filtered results\n",
    "        filtered_df = pd.DataFrame()\n",
    "        location, extension = os.path.splitext(file_name)\n",
    "        # Loop through each row of the growth data frame (sws_spring_wheat)\n",
    "        for index, row in wheat_df.iterrows():\n",
    "            if row['location'] == location:\n",
    "                year = row['planting date'].year - 1\n",
    "                start_date = datetime.strptime(f'10/1/{year}', '%m/%d/%Y')\n",
    "                \n",
    "                # Apply the date filtering\n",
    "                mask = (loc_df['date'] >= start_date) & (loc_df['date'] < row['planting date'])\n",
    "                filtered_data = loc_df[mask]\n",
    "               # Calculate the total precipitation for the year\n",
    "                yearly_pre_var_sums[year +1] = filtered_data['spei'].sum()\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        pre_var_df = pd.DataFrame(list(yearly_pre_var_sums.items()), columns=['year', 'preseason_spei'])\n",
    "        \n",
    "        # Save the DataFrame to the output directory\n",
    "        output_file_path = os.path.join(output_path, f'{location}.xlsx')\n",
    "        pre_var_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd861f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to add the preseason to the reshaped data\n",
    "directory = './pr_season'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") :  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "# read the reshaped data\n",
    "reshaped_df = pd.read_excel('./reshaped_combined_gs.xlsx')\n",
    "\n",
    "reshaped_df = reshaped_df.merge(combined_df[['year', 'location', 'preseason_precip']], on=['year', 'location'], how='left')\n",
    "# save the reshaped data\n",
    "reshaped_df.to_excel('./reshaped_combined_gs_with_preseason.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#### I want to merge soil static data    ####\n",
    "#############################################\n",
    "import pandas as pd\n",
    "df_soil = pd.read_excel('./soil_data/locations.xlsx')\n",
    "#df_soil = df_soil.drop(columns = ['Latitude', 'Longitude'])\n",
    "\n",
    "# read environment file and merge it with crop trait\n",
    "df_env = pd.read_csv('f_data_gs2.csv')\n",
    "df_merged = df_soil.merge(df_env, on = ['location'], how = 'left')\n",
    "df_merged.to_csv('./df_22805.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
