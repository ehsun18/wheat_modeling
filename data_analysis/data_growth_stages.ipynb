{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#     Filter the dates based on planting and harvesting date    #\n",
    "#################################################################\n",
    "loc_files = './soil'\n",
    "\n",
    "wheat_df = pd.read_excel('sws_spring_wheat.xlsx',sheet_name='Sheet2')\n",
    "for file_name in os.listdir(loc_files):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Load the datasets\n",
    "        file_path = os.path.join(loc_files,file_name)\n",
    "        loc_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "        # Convert date columns to datetime format\n",
    "        loc_df['date'] = pd.to_datetime(loc_df['date'])\n",
    "        wheat_df['planting date'] = pd.to_datetime(wheat_df['planting date'])\n",
    "        wheat_df['harvest date'] = pd.to_datetime(wheat_df['harvest date'])\n",
    "\n",
    "        # Initialize an empty DataFrame to store the filtered results\n",
    "        filtered_df = pd.DataFrame()\n",
    "        location, extension = os.path.splitext(file_name)\n",
    "        # Loop through each row of the growth data frame (sws_spring_wheat)\n",
    "        for index, row in wheat_df.iterrows():\n",
    "            if row['location'] == location:\n",
    "                # Filter rows where the date is between the planting and harvest dates for the respective year\n",
    "                mask = (loc_df['date'] >= row['planting date']) & (loc_df['date'] <= row['harvest date'])\n",
    "                filtered_data = loc_df[mask]\n",
    "                # Append the filtered data to the filtered_df\n",
    "                filtered_df = pd.concat([filtered_df, filtered_data], ignore_index=True)\n",
    "                \n",
    "        output_file_path = os.path.join('./soil_p_h', f'{file_name}')\n",
    "        filtered_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding drought indeces to the data, they are in 5-days resolution, in contrast with other data ###\n",
    "file_path1 = './test'\n",
    "file_path2 = './pdsi_p_h'\n",
    "output_path = './p_h_with_strs'\n",
    "excel_files = [f for f in os.listdir(file_path1) if f.endswith('.xlsx')]\n",
    "\n",
    "for excel_f in excel_files:\n",
    "    df1 = pd.read_excel(os.path.join(file_path1, excel_f))\n",
    "    df2 = pd.read_excel(os.path.join(file_path2, excel_f))\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "    df2['date'] = pd.to_datetime(df2['date'])\n",
    "    # Mergge according to the data\n",
    "    df1 = df1.merge(df2[['date', 'pdsi']], on = 'date', how = 'left')\n",
    "    output_file = os.path.join(output_path, f'{os.path.splitext(excel_f)[0]}.xlsx')\n",
    "    df1.to_excel(output_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
      "C:\\Users\\e.norouzikandlati\\AppData\\Local\\Temp\\ipykernel_164096\\1318871724.py:44: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n"
     ]
    }
   ],
   "source": [
    "## Set dataframe. Taking average or sum of variables, considering which one makes sense, during their repsective growth stage ##\n",
    "\n",
    "file_path = './test1/'\n",
    "\n",
    "# gs here stands for growth stage ##\n",
    "output_file_path = './gs_data/'\n",
    "# List all .xlsx files in the directory\n",
    "excel_files = [f for f in os.listdir(file_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Loop through each Excel file\n",
    "for excel_f in excel_files:\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(os.path.join(file_path, excel_f))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    gs_agg = df.groupby(['stage', 'year']).agg({\n",
    "            'precip': 'sum',\n",
    "            'tmax': 'mean',\n",
    "            'tmin': 'mean',\n",
    "            'Tavg': 'mean',\n",
    "            'gdd': 'sum',\n",
    "            'dgdd': 'sum',\n",
    "            'dtr': 'mean',\n",
    "            'prdtr': 'mean',\n",
    "            'pet': 'sum',\n",
    "            'etr': 'mean',\n",
    "            'srad': 'mean',\n",
    "            'rmax': 'mean',\n",
    "            'rmin': 'mean',\n",
    "            'vs': 'mean',\n",
    "            'ravg': 'mean',\n",
    "            'vpd': 'mean',\n",
    "            'fdd':'sum',\n",
    "            'hdd':'sum',\n",
    "            'spei':'mean',\n",
    "            'pdsi':'mean',\n",
    "            'soil':'mean'}).reset_index()\n",
    "    stage_order = {\"Emergence\": 0, \"Tillering\": 1, \"Jointing\": 2, \"Heading\": 3, \"Flowering\": 4, \"Grain fill\": 5, \"Maturity\": 6, \"Beyond Maturity\": 7}\n",
    "    gs_agg[\"stage_order\"] = gs_agg[\"stage\"].map(stage_order)\n",
    "    gs_agg = gs_agg.sort_values(by=[\"stage_order\",\"year\"]).drop(columns=\"stage_order\")\n",
    "    gs_agg = gs_agg.reset_index(drop=True)\n",
    "\n",
    "    # Calculate the number of days in each stage grouped by 'year' and 'stage'\n",
    "    days_per_stage_year = df.groupby(['year', 'stage'])['dap'].agg(lambda x: x.max() - x.min()).reset_index()\n",
    "    days_per_stage_year.rename(columns={'dap': '#days'}, inplace=True)\n",
    "\n",
    "    # Calculate the total number of wet days in each stage grouped by 'year' and 'stage'\n",
    "    wet_per_stage_year = df.groupby(['year', 'stage'])['wet'].agg(sum).reset_index()\n",
    "    wet_per_stage_year.rename(columns={'wet': '#wet'}, inplace=True)\n",
    "\n",
    "    # Merge the calculated values back into the aggregated dataset\n",
    "    gs_agg = gs_agg.merge(days_per_stage_year, on=['year', 'stage'], how='left')\n",
    "    gs_agg = gs_agg.merge(wet_per_stage_year, on=['year', 'stage'], how='left')\n",
    "\n",
    "    # Calculate wet frequency\n",
    "    gs_agg['wet_frequency'] = gs_agg['#wet'] / gs_agg['#days']\n",
    "\n",
    "    # Save the output to an Excel file\n",
    "    output_file = os.path.join(output_file_path, f'{os.path.splitext(excel_f)[0]}.xlsx')\n",
    "    gs_agg.to_excel(output_file, index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>year</th>\n",
       "      <th>precip</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>gdd</th>\n",
       "      <th>dgdd</th>\n",
       "      <th>dtr</th>\n",
       "      <th>prdtr</th>\n",
       "      <th>...</th>\n",
       "      <th>rmax</th>\n",
       "      <th>rmin</th>\n",
       "      <th>vs</th>\n",
       "      <th>ravg</th>\n",
       "      <th>vpd</th>\n",
       "      <th>fdd</th>\n",
       "      <th>hdd</th>\n",
       "      <th>spei</th>\n",
       "      <th>pdsi</th>\n",
       "      <th>#days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2005</td>\n",
       "      <td>40.4</td>\n",
       "      <td>13.578462</td>\n",
       "      <td>2.416154</td>\n",
       "      <td>7.997308</td>\n",
       "      <td>103.965</td>\n",
       "      <td>28.590</td>\n",
       "      <td>11.162308</td>\n",
       "      <td>0.272920</td>\n",
       "      <td>...</td>\n",
       "      <td>83.046154</td>\n",
       "      <td>35.592308</td>\n",
       "      <td>5.546154</td>\n",
       "      <td>59.319231</td>\n",
       "      <td>0.526154</td>\n",
       "      <td>28.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.496667</td>\n",
       "      <td>-3.253333</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.897500</td>\n",
       "      <td>6.020000</td>\n",
       "      <td>13.458750</td>\n",
       "      <td>107.670</td>\n",
       "      <td>25.880</td>\n",
       "      <td>14.877500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.875000</td>\n",
       "      <td>31.350000</td>\n",
       "      <td>3.675000</td>\n",
       "      <td>46.612500</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-1.570000</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2007</td>\n",
       "      <td>31.3</td>\n",
       "      <td>14.910909</td>\n",
       "      <td>3.329091</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>100.320</td>\n",
       "      <td>34.195</td>\n",
       "      <td>11.581818</td>\n",
       "      <td>0.319230</td>\n",
       "      <td>...</td>\n",
       "      <td>87.581818</td>\n",
       "      <td>42.463636</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>65.022727</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>16.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.810000</td>\n",
       "      <td>-0.575000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.4</td>\n",
       "      <td>15.178333</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>8.729167</td>\n",
       "      <td>104.750</td>\n",
       "      <td>40.305</td>\n",
       "      <td>12.898333</td>\n",
       "      <td>0.057334</td>\n",
       "      <td>...</td>\n",
       "      <td>74.116667</td>\n",
       "      <td>32.958333</td>\n",
       "      <td>5.175000</td>\n",
       "      <td>53.537500</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>30.32</td>\n",
       "      <td>4.45</td>\n",
       "      <td>-0.566667</td>\n",
       "      <td>-2.273333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.858571</td>\n",
       "      <td>7.315714</td>\n",
       "      <td>15.087143</td>\n",
       "      <td>105.610</td>\n",
       "      <td>31.830</td>\n",
       "      <td>15.542857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.857143</td>\n",
       "      <td>31.085714</td>\n",
       "      <td>3.414286</td>\n",
       "      <td>45.971429</td>\n",
       "      <td>1.187143</td>\n",
       "      <td>1.16</td>\n",
       "      <td>12.10</td>\n",
       "      <td>-1.010000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.9</td>\n",
       "      <td>32.596970</td>\n",
       "      <td>18.667576</td>\n",
       "      <td>25.632273</td>\n",
       "      <td>843.220</td>\n",
       "      <td>59.665</td>\n",
       "      <td>13.929394</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>...</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>16.424242</td>\n",
       "      <td>3.612121</td>\n",
       "      <td>27.295455</td>\n",
       "      <td>2.786364</td>\n",
       "      <td>0.40</td>\n",
       "      <td>101.99</td>\n",
       "      <td>-1.504286</td>\n",
       "      <td>-3.165714</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.7</td>\n",
       "      <td>32.454872</td>\n",
       "      <td>14.759487</td>\n",
       "      <td>23.607179</td>\n",
       "      <td>920.680</td>\n",
       "      <td>66.040</td>\n",
       "      <td>17.695385</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>...</td>\n",
       "      <td>61.961538</td>\n",
       "      <td>20.543590</td>\n",
       "      <td>2.930769</td>\n",
       "      <td>41.252564</td>\n",
       "      <td>2.297692</td>\n",
       "      <td>27.66</td>\n",
       "      <td>126.54</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>-3.442500</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.440000</td>\n",
       "      <td>16.903684</td>\n",
       "      <td>26.171842</td>\n",
       "      <td>497.265</td>\n",
       "      <td>29.870</td>\n",
       "      <td>18.536316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>41.131579</td>\n",
       "      <td>12.715789</td>\n",
       "      <td>2.847368</td>\n",
       "      <td>26.923684</td>\n",
       "      <td>3.218421</td>\n",
       "      <td>6.53</td>\n",
       "      <td>104.67</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>-3.167500</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.9</td>\n",
       "      <td>32.439655</td>\n",
       "      <td>14.941034</td>\n",
       "      <td>23.690345</td>\n",
       "      <td>687.020</td>\n",
       "      <td>50.535</td>\n",
       "      <td>17.498621</td>\n",
       "      <td>0.028511</td>\n",
       "      <td>...</td>\n",
       "      <td>56.734483</td>\n",
       "      <td>18.896552</td>\n",
       "      <td>3.193103</td>\n",
       "      <td>37.815517</td>\n",
       "      <td>2.371724</td>\n",
       "      <td>22.14</td>\n",
       "      <td>82.76</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.608333</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.6</td>\n",
       "      <td>33.323333</td>\n",
       "      <td>15.803333</td>\n",
       "      <td>24.563333</td>\n",
       "      <td>735.050</td>\n",
       "      <td>61.050</td>\n",
       "      <td>17.520000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>...</td>\n",
       "      <td>51.636667</td>\n",
       "      <td>17.143333</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>34.390000</td>\n",
       "      <td>2.603333</td>\n",
       "      <td>18.90</td>\n",
       "      <td>116.40</td>\n",
       "      <td>-0.630000</td>\n",
       "      <td>-2.811667</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               stage  year  precip       tmax       tmin       Tavg      gdd  \\\n",
       "0          Emergence  2005    40.4  13.578462   2.416154   7.997308  103.965   \n",
       "1          Emergence  2006     0.0  20.897500   6.020000  13.458750  107.670   \n",
       "2          Emergence  2007    31.3  14.910909   3.329091   9.120000  100.320   \n",
       "3          Emergence  2008     9.4  15.178333   2.280000   8.729167  104.750   \n",
       "4          Emergence  2009     0.0  22.858571   7.315714  15.087143  105.610   \n",
       "..               ...   ...     ...        ...        ...        ...      ...   \n",
       "114  Beyond Maturity  2015     2.9  32.596970  18.667576  25.632273  843.220   \n",
       "115  Beyond Maturity  2016     3.7  32.454872  14.759487  23.607179  920.680   \n",
       "116  Beyond Maturity  2018     0.0  35.440000  16.903684  26.171842  497.265   \n",
       "117  Beyond Maturity  2019     9.9  32.439655  14.941034  23.690345  687.020   \n",
       "118  Beyond Maturity  2020     0.6  33.323333  15.803333  24.563333  735.050   \n",
       "\n",
       "       dgdd        dtr     prdtr  ...       rmax       rmin        vs  \\\n",
       "0    28.590  11.162308  0.272920  ...  83.046154  35.592308  5.546154   \n",
       "1    25.880  14.877500  0.000000  ...  61.875000  31.350000  3.675000   \n",
       "2    34.195  11.581818  0.319230  ...  87.581818  42.463636  4.636364   \n",
       "3    40.305  12.898333  0.057334  ...  74.116667  32.958333  5.175000   \n",
       "4    31.830  15.542857  0.000000  ...  60.857143  31.085714  3.414286   \n",
       "..      ...        ...       ...  ...        ...        ...       ...   \n",
       "114  59.665  13.929394  0.007846  ...  38.166667  16.424242  3.612121   \n",
       "115  66.040  17.695385  0.008314  ...  61.961538  20.543590  2.930769   \n",
       "116  29.870  18.536316  0.000000  ...  41.131579  12.715789  2.847368   \n",
       "117  50.535  17.498621  0.028511  ...  56.734483  18.896552  3.193103   \n",
       "118  61.050  17.520000  0.001242  ...  51.636667  17.143333  3.260000   \n",
       "\n",
       "          ravg       vpd    fdd     hdd      spei      pdsi  #days  \n",
       "0    59.319231  0.526154  28.55    0.00 -1.496667 -3.253333     12  \n",
       "1    46.612500  1.035000   5.45    5.77 -1.570000 -1.270000      7  \n",
       "2    65.022727  0.520000  16.88    0.00 -0.810000 -0.575000     10  \n",
       "3    53.537500  0.705833  30.32    4.45 -0.566667 -2.273333     11  \n",
       "4    45.971429  1.187143   1.16   12.10 -1.010000  1.420000      6  \n",
       "..         ...       ...    ...     ...       ...       ...    ...  \n",
       "114  27.295455  2.786364   0.40  101.99 -1.504286 -3.165714     32  \n",
       "115  41.252564  2.297692  27.66  126.54  0.472500 -3.442500     38  \n",
       "116  26.923684  3.218421   6.53  104.67 -0.970000 -3.167500     18  \n",
       "117  37.815517  2.371724  22.14   82.76  0.125000  1.608333     28  \n",
       "118  34.390000  2.603333  18.90  116.40 -0.630000 -2.811667     29  \n",
       "\n",
       "[119 rows x 23 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all data frames ##\n",
    "directory = './gs_data'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\"):  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df = combined_df.drop(columns = ['#wet'])\n",
    "combined_df.to_excel('./combined_gs.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>year</th>\n",
       "      <th>precip</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>gdd</th>\n",
       "      <th>dgdd</th>\n",
       "      <th>dtr</th>\n",
       "      <th>prdtr</th>\n",
       "      <th>...</th>\n",
       "      <th>ravg</th>\n",
       "      <th>vpd</th>\n",
       "      <th>fdd</th>\n",
       "      <th>hdd</th>\n",
       "      <th>spei</th>\n",
       "      <th>pdsi</th>\n",
       "      <th>soil</th>\n",
       "      <th>#days</th>\n",
       "      <th>wet_frequency</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2005</td>\n",
       "      <td>8.7</td>\n",
       "      <td>17.675455</td>\n",
       "      <td>2.147273</td>\n",
       "      <td>9.911364</td>\n",
       "      <td>109.025</td>\n",
       "      <td>17.860</td>\n",
       "      <td>15.528182</td>\n",
       "      <td>0.053153</td>\n",
       "      <td>...</td>\n",
       "      <td>55.418182</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>28.90</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>-4.035000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Almira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.030000</td>\n",
       "      <td>2.763636</td>\n",
       "      <td>9.896818</td>\n",
       "      <td>108.865</td>\n",
       "      <td>41.200</td>\n",
       "      <td>14.266364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.918182</td>\n",
       "      <td>0.757273</td>\n",
       "      <td>23.78</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Almira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.837000</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>10.976000</td>\n",
       "      <td>109.760</td>\n",
       "      <td>26.720</td>\n",
       "      <td>13.722000</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>...</td>\n",
       "      <td>53.960000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>-1.045000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Almira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.5</td>\n",
       "      <td>15.245000</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>8.130833</td>\n",
       "      <td>97.570</td>\n",
       "      <td>50.445</td>\n",
       "      <td>14.228333</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>...</td>\n",
       "      <td>53.150000</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>46.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>-2.810000</td>\n",
       "      <td>15.1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>Almira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergence</td>\n",
       "      <td>2009</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16.260000</td>\n",
       "      <td>2.015000</td>\n",
       "      <td>9.137500</td>\n",
       "      <td>109.650</td>\n",
       "      <td>31.135</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>...</td>\n",
       "      <td>50.495833</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>37.23</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-2.716667</td>\n",
       "      <td>15.9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>Almira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.9</td>\n",
       "      <td>32.596970</td>\n",
       "      <td>18.667576</td>\n",
       "      <td>25.632273</td>\n",
       "      <td>843.220</td>\n",
       "      <td>59.665</td>\n",
       "      <td>13.929394</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>...</td>\n",
       "      <td>27.295455</td>\n",
       "      <td>2.786364</td>\n",
       "      <td>0.40</td>\n",
       "      <td>101.99</td>\n",
       "      <td>-1.504286</td>\n",
       "      <td>-3.165714</td>\n",
       "      <td>12.2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>Walla Walla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.7</td>\n",
       "      <td>32.454872</td>\n",
       "      <td>14.759487</td>\n",
       "      <td>23.607179</td>\n",
       "      <td>920.680</td>\n",
       "      <td>66.040</td>\n",
       "      <td>17.695385</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>...</td>\n",
       "      <td>41.252564</td>\n",
       "      <td>2.297692</td>\n",
       "      <td>27.66</td>\n",
       "      <td>126.54</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>-3.442500</td>\n",
       "      <td>12.3</td>\n",
       "      <td>38</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>Walla Walla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.440000</td>\n",
       "      <td>16.903684</td>\n",
       "      <td>26.171842</td>\n",
       "      <td>497.265</td>\n",
       "      <td>29.870</td>\n",
       "      <td>18.536316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.923684</td>\n",
       "      <td>3.218421</td>\n",
       "      <td>6.53</td>\n",
       "      <td>104.67</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>-3.167500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Walla Walla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.9</td>\n",
       "      <td>32.439655</td>\n",
       "      <td>14.941034</td>\n",
       "      <td>23.690345</td>\n",
       "      <td>687.020</td>\n",
       "      <td>50.535</td>\n",
       "      <td>17.498621</td>\n",
       "      <td>0.028511</td>\n",
       "      <td>...</td>\n",
       "      <td>37.815517</td>\n",
       "      <td>2.371724</td>\n",
       "      <td>22.14</td>\n",
       "      <td>82.76</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.608333</td>\n",
       "      <td>14.4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>Walla Walla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>Beyond Maturity</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.6</td>\n",
       "      <td>33.323333</td>\n",
       "      <td>15.803333</td>\n",
       "      <td>24.563333</td>\n",
       "      <td>735.050</td>\n",
       "      <td>61.050</td>\n",
       "      <td>17.520000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>...</td>\n",
       "      <td>34.390000</td>\n",
       "      <td>2.603333</td>\n",
       "      <td>18.90</td>\n",
       "      <td>116.40</td>\n",
       "      <td>-0.630000</td>\n",
       "      <td>-2.811667</td>\n",
       "      <td>11.4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>Walla Walla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1814 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                stage  year  precip       tmax       tmin       Tavg      gdd  \\\n",
       "0           Emergence  2005     8.7  17.675455   2.147273   9.911364  109.025   \n",
       "1           Emergence  2006     0.0  17.030000   2.763636   9.896818  108.865   \n",
       "2           Emergence  2007     2.0  17.837000   4.115000  10.976000  109.760   \n",
       "3           Emergence  2008     2.5  15.245000   1.016667   8.130833   97.570   \n",
       "4           Emergence  2009     3.3  16.260000   2.015000   9.137500  109.650   \n",
       "...               ...   ...     ...        ...        ...        ...      ...   \n",
       "1809  Beyond Maturity  2015     2.9  32.596970  18.667576  25.632273  843.220   \n",
       "1810  Beyond Maturity  2016     3.7  32.454872  14.759487  23.607179  920.680   \n",
       "1811  Beyond Maturity  2018     0.0  35.440000  16.903684  26.171842  497.265   \n",
       "1812  Beyond Maturity  2019     9.9  32.439655  14.941034  23.690345  687.020   \n",
       "1813  Beyond Maturity  2020     0.6  33.323333  15.803333  24.563333  735.050   \n",
       "\n",
       "        dgdd        dtr     prdtr  ...       ravg       vpd    fdd     hdd  \\\n",
       "0     17.860  15.528182  0.053153  ...  55.418182  0.781818  28.90    2.32   \n",
       "1     41.200  14.266364  0.000000  ...  52.918182  0.757273  23.78    0.66   \n",
       "2     26.720  13.722000  0.015775  ...  53.960000  0.775000   8.83    0.00   \n",
       "3     50.445  14.228333  0.017236  ...  53.150000  0.709167  46.29    0.00   \n",
       "4     31.135  14.245000  0.026269  ...  50.495833  0.815000  37.23    4.71   \n",
       "...      ...        ...       ...  ...        ...       ...    ...     ...   \n",
       "1809  59.665  13.929394  0.007846  ...  27.295455  2.786364   0.40  101.99   \n",
       "1810  66.040  17.695385  0.008314  ...  41.252564  2.297692  27.66  126.54   \n",
       "1811  29.870  18.536316  0.000000  ...  26.923684  3.218421   6.53  104.67   \n",
       "1812  50.535  17.498621  0.028511  ...  37.815517  2.371724  22.14   82.76   \n",
       "1813  61.050  17.520000  0.001242  ...  34.390000  2.603333  18.90  116.40   \n",
       "\n",
       "          spei      pdsi  soil  #days  wet_frequency     location  \n",
       "0     0.135000 -4.035000   NaN     10       0.500000       Almira  \n",
       "1     0.885000  2.320000   NaN     10       0.000000       Almira  \n",
       "2    -0.070000 -1.045000   NaN      9       0.222222       Almira  \n",
       "3     0.175000 -2.810000  15.1     11       0.181818       Almira  \n",
       "4    -0.666667 -2.716667  15.9     11       0.181818       Almira  \n",
       "...        ...       ...   ...    ...            ...          ...  \n",
       "1809 -1.504286 -3.165714  12.2     32       0.093750  Walla Walla  \n",
       "1810  0.472500 -3.442500  12.3     38       0.052632  Walla Walla  \n",
       "1811 -0.970000 -3.167500   NaN     18       0.000000  Walla Walla  \n",
       "1812  0.125000  1.608333  14.4     28       0.142857  Walla Walla  \n",
       "1813 -0.630000 -2.811667  11.4     29       0.034483  Walla Walla  \n",
       "\n",
       "[1814 rows x 26 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rehape the data so it will have columns based on growth stage and evironmental variable ###\n",
    "\n",
    "# Define the order of the stages\n",
    "stage_order = [\"Emergence\", \"Tillering\", \"mature\", \"Jointing\", \"Heading\", \"Flowering\", \"Grain fill\", \"Maturity\", \"Beyond Maturity\"]  \n",
    "\n",
    "# Convert 'stage' to a categorical type with the specified order\n",
    "combined_df[\"stage\"] = pd.Categorical(combined_df[\"stage\"], categories=stage_order, ordered=True)\n",
    "\n",
    "# Pivot the data\n",
    "reshaped_df = combined_df.pivot(index=[\"year\", \"location\"], columns=\"stage\")\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "reshaped_df.columns = [f\"{col[1]}_{col[0]}\" for col in reshaped_df.columns]\n",
    "\n",
    "# Reset the index for a clean format\n",
    "reshaped_df.reset_index(inplace=True)\n",
    "# Save the reshaped DataFrame to an Excel file\n",
    "reshaped_df.to_excel('./reshaped_combined_gs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>Emergence_precip</th>\n",
       "      <th>Tillering_precip</th>\n",
       "      <th>Jointing_precip</th>\n",
       "      <th>Heading_precip</th>\n",
       "      <th>Flowering_precip</th>\n",
       "      <th>Grain fill_precip</th>\n",
       "      <th>Maturity_precip</th>\n",
       "      <th>Beyond Maturity_precip</th>\n",
       "      <th>...</th>\n",
       "      <th>Maturity_#days</th>\n",
       "      <th>Beyond Maturity_#days</th>\n",
       "      <th>Emergence_wet_frequency</th>\n",
       "      <th>Tillering_wet_frequency</th>\n",
       "      <th>Jointing_wet_frequency</th>\n",
       "      <th>Heading_wet_frequency</th>\n",
       "      <th>Flowering_wet_frequency</th>\n",
       "      <th>Grain fill_wet_frequency</th>\n",
       "      <th>Maturity_wet_frequency</th>\n",
       "      <th>Beyond Maturity_wet_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>Almira</td>\n",
       "      <td>8.7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>Bickleton</td>\n",
       "      <td>19.6</td>\n",
       "      <td>42.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>Connell</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>3.6</td>\n",
       "      <td>81.8</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>5.9</td>\n",
       "      <td>79.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2020</td>\n",
       "      <td>Plaza</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2020</td>\n",
       "      <td>Pullman</td>\n",
       "      <td>4.2</td>\n",
       "      <td>73.1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2020</td>\n",
       "      <td>Reardan</td>\n",
       "      <td>7.8</td>\n",
       "      <td>72.3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2020</td>\n",
       "      <td>St. John</td>\n",
       "      <td>15.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>62.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2020</td>\n",
       "      <td>Walla Walla</td>\n",
       "      <td>15.1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year     location  Emergence_precip  Tillering_precip  Jointing_precip  \\\n",
       "0    2005       Almira               8.7              53.1              3.9   \n",
       "1    2005    Bickleton              19.6              42.2              7.3   \n",
       "2    2005      Connell               0.3              30.2              6.5   \n",
       "3    2005       Dayton               3.6              81.8             29.8   \n",
       "4    2005    Fairfield               5.9              79.6             21.3   \n",
       "..    ...          ...               ...               ...              ...   \n",
       "224  2020        Plaza               6.0              83.0             26.4   \n",
       "225  2020      Pullman               4.2              73.1             25.6   \n",
       "226  2020      Reardan               7.8              72.3             34.5   \n",
       "227  2020     St. John              15.4              29.8             62.3   \n",
       "228  2020  Walla Walla              15.1              11.4             32.2   \n",
       "\n",
       "     Heading_precip  Flowering_precip  Grain fill_precip  Maturity_precip  \\\n",
       "0              20.9               4.1               11.4              0.0   \n",
       "1               3.3               0.0                1.9              0.0   \n",
       "2              26.1               7.4                2.0              3.5   \n",
       "3              53.4               3.2               15.2              0.0   \n",
       "4              22.1              18.1                0.3              0.0   \n",
       "..              ...               ...                ...              ...   \n",
       "224            36.5               0.0                0.0              1.2   \n",
       "225            27.9               0.4                0.0              2.0   \n",
       "226            28.4               0.0                0.0              1.8   \n",
       "227            26.7               5.9                0.0              0.0   \n",
       "228            62.6              13.4                1.1              1.3   \n",
       "\n",
       "     Beyond Maturity_precip  ...  Maturity_#days  Beyond Maturity_#days  \\\n",
       "0                       0.0  ...             4.0                   16.0   \n",
       "1                       NaN  ...             3.0                    NaN   \n",
       "2                       3.3  ...             5.0                   11.0   \n",
       "3                       0.0  ...             4.0                    9.0   \n",
       "4                      10.1  ...             4.0                   14.0   \n",
       "..                      ...  ...             ...                    ...   \n",
       "224                     0.7  ...             6.0                   15.0   \n",
       "225                     1.4  ...             6.0                   10.0   \n",
       "226                     0.0  ...             6.0                   23.0   \n",
       "227                     0.4  ...             4.0                   11.0   \n",
       "228                     0.6  ...             5.0                   29.0   \n",
       "\n",
       "     Emergence_wet_frequency  Tillering_wet_frequency  Jointing_wet_frequency  \\\n",
       "0                   0.500000                 0.391304                0.153846   \n",
       "1                   0.500000                 0.500000                0.277778   \n",
       "2                   0.111111                 0.400000                0.266667   \n",
       "3                   0.181818                 0.555556                0.500000   \n",
       "4                   0.500000                 0.592593                0.437500   \n",
       "..                       ...                      ...                     ...   \n",
       "224                 0.076923                 0.517241                0.375000   \n",
       "225                 0.181818                 0.428571                0.312500   \n",
       "226                 0.272727                 0.551724                0.466667   \n",
       "227                 0.411765                 0.172414                0.500000   \n",
       "228                 0.500000                 0.259259                0.500000   \n",
       "\n",
       "     Heading_wet_frequency  Flowering_wet_frequency  Grain fill_wet_frequency  \\\n",
       "0                 0.200000                 0.111111                  0.176471   \n",
       "1                 0.166667                 0.000000                  0.066667   \n",
       "2                 0.416667                 0.166667                  0.187500   \n",
       "3                 0.500000                 0.300000                  0.315789   \n",
       "4                 0.346154                 0.400000                  0.058824   \n",
       "..                     ...                      ...                       ...   \n",
       "224               0.423077                 0.000000                  0.000000   \n",
       "225               0.346154                 0.100000                  0.000000   \n",
       "226               0.423077                 0.000000                  0.000000   \n",
       "227               0.333333                 0.363636                  0.000000   \n",
       "228               0.440000                 0.555556                  0.058824   \n",
       "\n",
       "     Maturity_wet_frequency  Beyond Maturity_wet_frequency  \n",
       "0                  0.000000                       0.000000  \n",
       "1                  0.000000                            NaN  \n",
       "2                  0.200000                       0.181818  \n",
       "3                  0.000000                       0.000000  \n",
       "4                  0.000000                       0.142857  \n",
       "..                      ...                            ...  \n",
       "224                0.166667                       0.066667  \n",
       "225                0.166667                       0.200000  \n",
       "226                0.166667                       0.000000  \n",
       "227                0.000000                       0.090909  \n",
       "228                0.200000                       0.034483  \n",
       "\n",
       "[229 rows x 186 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "## I want to add precipitation (or any other variable) before each growing season to the data  ##\n",
    "## I will sum up the precipitation from october until planting date to the data                ##\n",
    "#################################################################################################\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "loc_files = './spei' \n",
    "output_path = './spei_season'\n",
    "wheat_df = pd.read_excel('sws_spring_wheat.xlsx',sheet_name='Sheet2')\n",
    "yearly_precip_sums = {}\n",
    "for file_name in os.listdir(loc_files):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Load the datasets\n",
    "        file_path = os.path.join(loc_files,file_name)\n",
    "        loc_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "        # Convert date columns to datetime format\n",
    "        loc_df['date'] = pd.to_datetime(loc_df['date'])\n",
    "        wheat_df['planting date'] = pd.to_datetime(wheat_df['planting date'])\n",
    "        #wheat_df['harvest date'] = pd.to_datetime(wheat_df['harvest date'])\n",
    "\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the filtered results\n",
    "        filtered_df = pd.DataFrame()\n",
    "        location, extension = os.path.splitext(file_name)\n",
    "        # Loop through each row of the growth data frame (sws_spring_wheat)\n",
    "        for index, row in wheat_df.iterrows():\n",
    "            if row['location'] == location:\n",
    "                year = row['planting date'].year - 1\n",
    "                start_date = datetime.strptime(f'10/1/{year}', '%m/%d/%Y')\n",
    "                \n",
    "                # Apply the date filtering\n",
    "                mask = (loc_df['date'] >= start_date) & (loc_df['date'] < row['planting date'])\n",
    "                filtered_data = loc_df[mask]\n",
    "               # Calculate the total precipitation for the year\n",
    "                yearly_pre_var_sums[year +1] = filtered_data['spei'].sum()\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        pre_var_df = pd.DataFrame(list(yearly_pre_var_sums.items()), columns=['year', 'preseason_spei'])\n",
    "        \n",
    "        # Save the DataFrame to the output directory\n",
    "        output_file_path = os.path.join(output_path, f'{location}.xlsx')\n",
    "        pre_var_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './pr_season'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") :  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "# read the reshaped data\n",
    "reshaped_df = pd.read_excel('./reshaped_combined_gs.xlsx')\n",
    "\n",
    "reshaped_df = reshaped_df.merge(combined_df[['year', 'location', 'preseason_precip']], on=['year', 'location'], how='left')\n",
    "reshaped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "## I want to add soil moisture (or other variables) before each growing season to the data.                        ##\n",
    "## I will sum up the soil moisture (or other variables) from october until planting date to the data               ##\n",
    "#####################################################################################################################\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "loc_files = 'pdsi'\n",
    "output_path = './pdsi_season'\n",
    "wheat_df = pd.read_excel('sws_spring_wheat.xlsx',sheet_name='Sheet2')\n",
    "yearly_pdsi_sums = {}\n",
    "for file_name in os.listdir(loc_files):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Load the datasets\n",
    "        file_path = os.path.join(loc_files,file_name)\n",
    "        loc_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "        # Convert date columns to datetime format\n",
    "        loc_df['date'] = pd.to_datetime(loc_df['date'])\n",
    "        wheat_df['planting date'] = pd.to_datetime(wheat_df['planting date'])\n",
    "        #wheat_df['harvest date'] = pd.to_datetime(wheat_df['harvest date'])\n",
    "\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the filtered results\n",
    "        filtered_df = pd.DataFrame()\n",
    "        location, extension = os.path.splitext(file_name)\n",
    "        # Loop through each row of the growth data frame (sws_spring_wheat)\n",
    "        for index, row in wheat_df.iterrows():\n",
    "            if row['location'] == location:\n",
    "                year = row['planting date'].year - 1\n",
    "                start_date = datetime.strptime(f'10/1/{year}', '%m/%d/%Y')\n",
    "                \n",
    "                # Apply the date filtering\n",
    "                mask = (loc_df['date'] >= start_date) & (loc_df['date'] < row['planting date'])\n",
    "                filtered_data = loc_df[mask]\n",
    "               # Calculate the total pdsi for the year\n",
    "                yearly_pdsi_sums[year +1] = filtered_data['pdsi'].mean()\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        pdsi_df = pd.DataFrame(list(yearly_pdsi_sums.items()), columns=['year', 'preseason_pdsi'])\n",
    "        \n",
    "        # Save the DataFrame to the output directory\n",
    "        output_file_path = os.path.join(output_path, f'{location}.xlsx')\n",
    "        pdsi_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './soil_season'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") :  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.to_excel('./combined_soil_season.xlsx', index=False)\n",
    "df_pre_soil = df_pre_precip.merge(combined_df[['year', 'location', 'preseason_soil']], on=['year', 'location'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1= pd.read_csv('f_data_gs.csv')\n",
    "directory = './temp_season'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") :  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "#combined_df.to_excel('./combined_soil_season.xlsx', index=False)\n",
    "df_pre_temp = df_pre_soil.merge(combined_df[['year', 'location', 'preseason_temp']], on=['year', 'location'], how='left')\n",
    "df_pre_temp.to_csv('f_data_gs1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df1= pd.read_csv('data_f.csv')\n",
    "directory = './pdsi_season'\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\") :  # check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(filepath)\n",
    "        \n",
    "        location, extension = os.path.splitext(filename)\n",
    "\n",
    "        # Add a column with the filename (without extension)\n",
    "        df['location'] = location\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "#combined_df.to_excel('./combined_soil_season.xlsx', index=False)\n",
    "df_pre_temp = df_pre_temp.merge(combined_df[['year', 'location', 'preseason_pdsi']], on=['year', 'location'], how='left')\n",
    "df_pre_temp.to_csv('f_data_gs2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### preseason SPEI #####\n",
    "#########################\n",
    "\n",
    "\n",
    "# Read the main CSV file\n",
    "df_main = pd.read_csv('df_22805_v1.csv')\n",
    "\n",
    "# Directory containing Excel files\n",
    "directory = './spei_season'\n",
    "\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\"):  # Check for Excel files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        # Read the Excel file\n",
    "        df_spei = pd.read_excel(filepath)\n",
    "\n",
    "        # Extract location from filename\n",
    "        location, _ = os.path.splitext(filename)\n",
    "        df_spei['location'] = location  # Add location column\n",
    "\n",
    "        # Append dataframe to the list\n",
    "        dataframes.append(df_spei)\n",
    "\n",
    "# Combine all SPEI data\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Merge with main DataFrame\n",
    "df_main = df_main.merge(combined_df[['year', 'location', 'preseason_spei']], \n",
    "                        on=['year', 'location'], how='left')\n",
    "\n",
    "# Save the updated CSV\n",
    "df_main.to_csv('df_22805_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'Athena-Spofford silt loams': 0, 'Bagdad silt loam': 1, 'Lickskillet silt loam': 2, 'Lickskillet-Schuelke-Rock outcrop complex': 3, 'Palouse silt loam': 4, 'Ritzville silt loam': 5, 'Roloff-Bakeoven-Rock outcrop complex': 6, 'Thatuna silt loam': 7}\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "###   Encode soil type  ###\n",
    "###########################\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_main = pd.read_csv('df_22805_v2.csv')\n",
    "# Assuming 'soil_type' is the column in your DataFrame\n",
    "label_encoder = LabelEncoder()\n",
    "df_main['soil_type_encoded'] = label_encoder.fit_transform(df_main['soil_type'])\n",
    "\n",
    "# Optional: Check the mapping\n",
    "soil_type_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Encoding Mapping:\", soil_type_mapping)\n",
    "df_main = df_main.drop('soil_type', axis = 1)\n",
    "df_main.rename(columns={\"soil_type_encoded\": \"Soil_type\"}, inplace=True)\n",
    "df_main.to_csv('df_22805_v3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## Removing stages after heading for heading_date  ##\n",
    "#####################################################\n",
    "df = pd.read_csv('df_22805.csv')\n",
    "# Remove columns that contain 'z' in their name\n",
    "df_filtered = df.drop(columns=[col for col in df.columns if any(keyword in col for keyword in ['Maturity', 'Flowering', 'Grain'])])\n",
    "df_filtered.to_csv('df_22805_hd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
